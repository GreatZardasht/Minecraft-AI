{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import mltools as ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to use the example from \n",
    "[http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/](http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**biome dataset**:  \n",
    "denote number of data  \n",
    "mesa size:  10015  \n",
    "forest size:  10047  \n",
    "desert size:  10106  \n",
    "jungle size:  10238  \n",
    "eh size:  7364  \n",
    "training size: 42993  \n",
    "test size: 4777  \n",
    "total size:  47770"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pig dataset:**  \n",
    "denote number of data  \n",
    "fence: 433  \n",
    "pig: 404 \n",
    "training size: 669  \n",
    "test size: 168  \n",
    "total size:  837"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels ={\"mesa\":0, \"forest\":1, \"desert\":2,\"jungle\":3,\"eh\":4}\n",
    "labels = {\"fence\":0, \"pig\":1}\n",
    "tfrecords_filename = '/notebooks/Minecraft-AI/mc-data/fence_pig_train.tfrecords'\n",
    "tfrecords_test_filename='/notebooks/Minecraft-AI/mc-data/fence_pig_test.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_paths = [\n",
    "    ('/notebooks/Minecraft-AI/mc-data/fence_rgb_2/*.jpg', \"0\"),\n",
    "    ('/notebooks/Minecraft-AI/mc-data/pig_rgb_2/*.jpg', \"1\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  0  size:  433\n",
      "label:  1  size:  404\n"
     ]
    }
   ],
   "source": [
    "filename_pairs=[]\n",
    "for file_name, label in files_paths:\n",
    "    files = glob.glob(file_name)\n",
    "    file_pairs = zip(files, label*len(files))\n",
    "    print \"label: \", label, \" size: \", len(files)\n",
    "    filename_pairs += file_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(filename_pairs)\n",
    "portion=int(0.8*len(filename_pairs))\n",
    "train_pairs = filename_pairs[:portion]\n",
    "test_pairs = filename_pairs[portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/notebooks/Minecraft-AI/mc-data/pig_rgb_2/pig_132.jpg', '1'), ('/notebooks/Minecraft-AI/mc-data/fence_rgb_2/fence_674.jpg', '0'), ('/notebooks/Minecraft-AI/mc-data/fence_rgb_2/fence_510.jpg', '0'), ('/notebooks/Minecraft-AI/mc-data/pig_rgb_2/pig_425.jpg', '1'), ('/notebooks/Minecraft-AI/mc-data/pig_rgb_2/pig_283.jpg', '1'), ('/notebooks/Minecraft-AI/mc-data/fence_rgb_2/fence_258.jpg', '0'), ('/notebooks/Minecraft-AI/mc-data/fence_rgb_2/fence_504.jpg', '0'), ('/notebooks/Minecraft-AI/mc-data/fence_rgb_2/fence_465.jpg', '0'), ('/notebooks/Minecraft-AI/mc-data/fence_rgb_2/fence_678.jpg', '0'), ('/notebooks/Minecraft-AI/mc-data/pig_rgb_2/pig_23.jpg', '1')]\n"
     ]
    }
   ],
   "source": [
    "print train_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 669\n",
      "test size: 168\n",
      "total size:  837\n"
     ]
    }
   ],
   "source": [
    "print \"training size:\", len(train_pairs)\n",
    "print \"test size:\", len(test_pairs)\n",
    "print \"total size: \", len(filename_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n",
    "test_writer = tf.python_io.TFRecordWriter(tfrecords_test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_in_tfrecord(filename_pairs, writer):\n",
    "    for img_path, label in filename_pairs:\n",
    "\n",
    "        img = np.array(Image.open(img_path))\n",
    "        \n",
    "        # The reason to store image sizes was demonstrated\n",
    "        # in the previous example -- we have to know sizes\n",
    "        # of images to later read raw serialized string,\n",
    "        # convert to 1d array and convert to respective\n",
    "        # shape that image used to have.\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "\n",
    "        # Put in the original images into array\n",
    "        # Just for future check for correctness\n",
    "#         original_images.append((img,label))\n",
    "\n",
    "        img_raw = img.tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(height),\n",
    "            'width': _int64_feature(width),\n",
    "            'image_raw': _bytes_feature(img_raw),\n",
    "            'label': _int64_feature(int(label))}))\n",
    "\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_in_tfrecord(train_pairs,train_writer)\n",
    "train_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_in_tfrecord(test_pairs,test_writer)\n",
    "test_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
