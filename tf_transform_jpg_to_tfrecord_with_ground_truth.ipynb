{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import mltools as ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to use the example from \n",
    "[http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/](http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "denote number of data  \n",
    "mesa: 10015  \n",
    "forest: 10047   \n",
    "desert: 10142  \n",
    "jungle size:  10238   \n",
    "eh size:  9261  \n",
    "training size: 39762  \n",
    "test size: 9941  \n",
    "total size:  49703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels ={\"mesa\":0, \"forest\":1, \"desert\":2,\"jungle\":3,\"eh\":4}\n",
    "tfrecords_filename = '/notebooks/Minecraft-AI/mc-data/mesa_forest_desert_jungle_train.tfrecords'\n",
    "tfrecords_test_filename='/notebooks/Minecraft-AI/mc-data/mesa_forest_desert_jungle_test.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesa_files = glob.glob( '/notebooks/Minecraft-AI/mc-data/mesa_splited/**/*.jpg')\n",
    "forest_files = glob.glob('/notebooks/Minecraft-AI/mc-data/forest_splited/**/*.jpg')\n",
    "desert_files = glob.glob('/notebooks/Minecraft-AI/mc-data/desert_splited/**/*.jpg')\n",
    "jungle_files = glob.glob('/notebooks/Minecraft-AI/mc-data/jungle_splited/**/*.jpg')\n",
    "# eh_files= glob.glob('/notebooks/Minecraft-AI/mc-data/eh_splited/**/*.jpg')\n",
    "mesa_pairs = zip(mesa_files, \"0\"*len(mesa_files))\n",
    "forest_pairs = zip(forest_files, \"1\"*len(forest_files))\n",
    "desert_pairs = zip(desert_files, \"2\"*len(desert_files))\n",
    "jungle_pairs = zip(jungle_files, \"3\"*len(jungle_files))\n",
    "eh_pairs = zip(eh_files, \"4\"*len(eh_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesa size:  10015\n",
      "forest size:  10047\n",
      "desert size:  10142\n",
      "jungle size:  10238\n",
      "eh size:  9261\n"
     ]
    }
   ],
   "source": [
    "print \"mesa size: \", len(mesa_pairs)\n",
    "print \"forest size: \", len(forest_pairs)\n",
    "print \"desert size: \", len(desert_pairs)\n",
    "print \"jungle size: \", len(jungle_pairs)\n",
    "print \"eh size: \", len(eh_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_pairs = mesa_pairs+forest_pairs+desert_pairs+jungle_pairs#+eh_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(filename_pairs)\n",
    "portion=int(0.8*len(filename_pairs))\n",
    "train_pairs = filename_pairs[:portion]\n",
    "test_pairs = filename_pairs[portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/notebooks/Minecraft-AI/mc-data/forest_splited/006/forest_3389.jpg', '1'), ('/notebooks/Minecraft-AI/mc-data/desert_splited/009/desert_8755.jpg', '2'), ('/notebooks/Minecraft-AI/mc-data/mesa_splited/003/mesa_2938.jpg', '0'), ('/notebooks/Minecraft-AI/mc-data/jungle_splited/005/jungle_5040.jpg', '3'), ('/notebooks/Minecraft-AI/mc-data/forest_splited/001/forest_10893.jpg', '1')]\n"
     ]
    }
   ],
   "source": [
    "print train_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 32353\n",
      "test size: 8089\n",
      "total size:  40442\n"
     ]
    }
   ],
   "source": [
    "print \"training size:\", len(train_pairs)\n",
    "print \"test size:\", len(test_pairs)\n",
    "print \"total size: \", len(filename_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n",
    "test_writer = tf.python_io.TFRecordWriter(tfrecords_test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's collect the real images to later on compare\n",
    "# to the reconstructed ones\n",
    "# original_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_in_tfrecord(filename_pairs, writer):\n",
    "    for img_path, label in filename_pairs:\n",
    "\n",
    "        img = np.array(Image.open(img_path))\n",
    "        \n",
    "        # The reason to store image sizes was demonstrated\n",
    "        # in the previous example -- we have to know sizes\n",
    "        # of images to later read raw serialized string,\n",
    "        # convert to 1d array and convert to respective\n",
    "        # shape that image used to have.\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "\n",
    "        # Put in the original images into array\n",
    "        # Just for future check for correctness\n",
    "#         original_images.append((img,label))\n",
    "\n",
    "        img_raw = img.tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(height),\n",
    "            'width': _int64_feature(width),\n",
    "            'image_raw': _bytes_feature(img_raw),\n",
    "            'label': _int64_feature(int(label))}))\n",
    "\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_in_tfrecord(train_pairs,train_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_in_tfrecord(test_pairs,test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
