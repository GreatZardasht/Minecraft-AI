{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import mltools as ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to use the example from \n",
    "[http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/](http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "denote number of data  \n",
    "mesa: 10015  \n",
    "forest: 10047   \n",
    "desert: 10142  \n",
    "training size: 21142  \n",
    "test size: 9062  \n",
    "total size:  30204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels ={\"mesa\":0, \"forest\":1, \"desert\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesa_files = glob.glob( '/notebooks/Minecraft-AI/mc-data/mesa_splited/**/*.jpg')\n",
    "forest_files = glob.glob('/notebooks/Minecraft-AI/mc-data/forest_splited/**/*.jpg')\n",
    "desert_files = glob.glob('/notebooks/Minecraft-AI/mc-data/desert_splited/**/*.jpg')\n",
    "mesa_pairs = zip(mesa_files, \"0\"*len(mesa_files))\n",
    "forest_pairs = zip(forest_files, \"1\"*len(forest_files))\n",
    "desert_pairs = zip(desert_files, \"2\"*len(desert_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesa size:  10015\n",
      "forest size:  10047\n",
      "desert size:  10142\n"
     ]
    }
   ],
   "source": [
    "print \"mesa size: \", len(mesa_pairs)\n",
    "print \"forest size: \", len(forest_pairs)\n",
    "print \"desert size: \", len(desert_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_pairs = mesa_pairs+forest_pairs+desert_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(filename_pairs)\n",
    "portion=int(0.7*len(filename_pairs))\n",
    "train_pairs = filename_pairs[:portion]\n",
    "test_pairs = filename_pairs[portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/notebooks/Minecraft-AI/mc-data/forest_splited/008/forest_7448.jpg', '1'), ('/notebooks/Minecraft-AI/mc-data/mesa_splited/006/mesa_6246.jpg', '0'), ('/notebooks/Minecraft-AI/mc-data/desert_splited/003/desert_3434.jpg', '2'), ('/notebooks/Minecraft-AI/mc-data/desert_splited/008/desert_7747.jpg', '2'), ('/notebooks/Minecraft-AI/mc-data/mesa_splited/001/mesa_1129.jpg', '0')]\n"
     ]
    }
   ],
   "source": [
    "print train_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training size: 21142\n",
      "test size: 9062\n",
      "total size:  30204\n"
     ]
    }
   ],
   "source": [
    "print \"training size:\", len(train_pairs)\n",
    "print \"test size:\", len(test_pairs)\n",
    "print \"total size: \", len(filename_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrecords_filename = '/notebooks/Minecraft-AI/mc-data/mesa_forest_desert_train.tfrecords'\n",
    "tfrecords_test_filename='/notebooks/Minecraft-AI/mc-data/mesa_forest_desert_test.tfrecords'\n",
    "train_writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n",
    "test_writer = tf.python_io.TFRecordWriter(tfrecords_test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's collect the real images to later on compare\n",
    "# to the reconstructed ones\n",
    "# original_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_in_tfrecord(filename_pairs, writer):\n",
    "    for img_path, label in filename_pairs:\n",
    "\n",
    "        img = np.array(Image.open(img_path))\n",
    "        \n",
    "        # The reason to store image sizes was demonstrated\n",
    "        # in the previous example -- we have to know sizes\n",
    "        # of images to later read raw serialized string,\n",
    "        # convert to 1d array and convert to respective\n",
    "        # shape that image used to have.\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "\n",
    "        # Put in the original images into array\n",
    "        # Just for future check for correctness\n",
    "#         original_images.append((img,label))\n",
    "\n",
    "        img_raw = img.tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(height),\n",
    "            'width': _int64_feature(width),\n",
    "            'image_raw': _bytes_feature(img_raw),\n",
    "            'label': _int64_feature(int(label))}))\n",
    "\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_in_tfrecord(train_pairs,train_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_in_tfrecord(test_pairs,test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
