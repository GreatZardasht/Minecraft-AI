{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import mltools as ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to use the example from \n",
    "[http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/](http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels ={\"mesa\":0, \"forest\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str([[1,0]]*len(files_rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/notebooks/Minecraft-AI/mc-data/forest/forest_rgb/forest_170.jpg'\n",
      " '/notebooks/Minecraft-AI/mc-data/forest/forest_d/forest_170_d.jpg' '1']\n"
     ]
    }
   ],
   "source": [
    "label = \"mesa\"\n",
    "files_rgb = sorted(glob.glob( \"/notebooks/Minecraft-AI/mc-data/\"+label+\"/\"+label+\"_rgb/*.jpg\"), key=lambda x:x.split(\"_\")[-1])\n",
    "files_d = sorted(glob.glob(\"/notebooks/Minecraft-AI/mc-data/\"+label+\"/\"+label+\"_d/*.jpg\"),key=lambda x:x.split(\"_\")[-2])\n",
    "filename_pairs = np.array(zip(files_rgb, files_d, [labels[label]]*len(files_rgb)))\n",
    "label= \"forest\"\n",
    "files_rgb = sorted(glob.glob( \"/notebooks/Minecraft-AI/mc-data/\"+label+\"/\"+label+\"_rgb/*.jpg\"), key=lambda x:x.split(\"_\")[-1])\n",
    "files_d = sorted(glob.glob(\"/notebooks/Minecraft-AI/mc-data/\"+label+\"/\"+label+\"_d/*.jpg\"),key=lambda x:x.split(\"_\")[-2])\n",
    "filename_pairs = np.concatenate((filename_pairs, np.array(zip(files_rgb, files_d, [labels[label]]*len(files_rgb))))\n",
    "                                , axis=0)\n",
    "np.random.shuffle(filename_pairs)\n",
    "portion=int(0.7*len(filename_pairs))\n",
    "train = filename_pairs[:portion]\n",
    "test = filename_pairs[portion:]\n",
    "print(filename_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfrecords_filename = '/notebooks/Minecraft-AI/mc-data/mesa_3_vs_forest_1_train.tfrecords'\n",
    "tfrecords_test_filename='/notebooks/Minecraft-AI/mc-data/mesa_3_vs_forest_1_test.tfrecords'\n",
    "train_writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n",
    "test_writer = tf.python_io.TFRecordWriter(tfrecords_test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's collect the real images to later on compare\n",
    "# to the reconstructed ones\n",
    "original_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_in_tfrecord(filename_pairs, writer):\n",
    "    for img_path, annotation_path, label in filename_pairs:\n",
    "\n",
    "        img = np.array(Image.open(img_path))\n",
    "        # jenny zeng modified for ground truth\n",
    "        annotation = (255 - np.array(Image.open(annotation_path)))\n",
    "        \n",
    "        # The reason to store image sizes was demonstrated\n",
    "        # in the previous example -- we have to know sizes\n",
    "        # of images to later read raw serialized string,\n",
    "        # convert to 1d array and convert to respective\n",
    "        # shape that image used to have.\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "\n",
    "        # Put in the original images into array\n",
    "        # Just for future check for correctness\n",
    "        original_images.append((img, annotation,label))\n",
    "\n",
    "        img_raw = img.tostring()\n",
    "        annotation_raw = annotation.tostring()\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(height),\n",
    "            'width': _int64_feature(width),\n",
    "            'image_raw': _bytes_feature(img_raw),\n",
    "            'mask_raw': _bytes_feature(annotation_raw),\n",
    "            'label': _int64_feature(int(label))}))\n",
    "\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_in_tfrecord(train,train_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_in_tfrecord(test,test_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reconstructed_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_test_filename)\n",
    "\n",
    "for string_record in record_iterator:\n",
    "    \n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(string_record)\n",
    "    \n",
    "    height = int(example.features.feature['height']\n",
    "                                 .int64_list\n",
    "                                 .value[0])\n",
    "    \n",
    "    width = int(example.features.feature['width']\n",
    "                                .int64_list\n",
    "                                .value[0])\n",
    "    \n",
    "    img_string = (example.features.feature['image_raw']\n",
    "                                  .bytes_list\n",
    "                                  .value[0])\n",
    "    \n",
    "    annotation_string = (example.features.feature['mask_raw']\n",
    "                                .bytes_list\n",
    "                                .value[0])\n",
    "    label = int(example.features.feature['label']\n",
    "                            .int64_list\n",
    "                            .value[0])\n",
    "    \n",
    "    img_1d = np.fromstring(img_string, dtype=np.uint8)\n",
    "    reconstructed_img = img_1d.reshape((height, width, -1))\n",
    "    \n",
    "    annotation_1d = np.fromstring(annotation_string, dtype=np.uint8)\n",
    "    \n",
    "    # Annotations don't have depth (3rd dimension)\n",
    "    reconstructed_annotation = annotation_1d.reshape((height, width))\n",
    "    \n",
    "    reconstructed_images.append((reconstructed_img, reconstructed_annotation, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(zip(original_images[0],reconstructed_images[0])))\n",
    "count=0\n",
    "print(zip(original_images[0],reconstructed_images[0])[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-7fa5ed81d50a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg_pair_to_compare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mannotation_pair_to_compare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlabel_pair_to_compare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m     \"\"\"\n\u001b[0;32m-> 2484\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mequal_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2485\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.pyc\u001b[0m in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2563\u001b[0;31m     \u001b[0mxfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2564\u001b[0m     \u001b[0myfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxfin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "# # Let's check if the reconstructed images match\n",
    "# # the original images\n",
    "for i in range(len(original_images)):\n",
    "    img_pair_to_compare, annotation_pair_to_compare, label_pair_to_compare = zip(original_images[i], reconstructed_images[i])\n",
    "\n",
    "# for original_pair, reconstructed_pair, label_pair in zip(original_images, reconstructed_images):\n",
    "#     img_pair_to_compare, annotation_pair_to_compare, label_pair_to_compare = zip(original_pair,\n",
    "#                                                           reconstructed_pair, label_pair)\n",
    "    print(np.allclose(*img_pair_to_compare))\n",
    "    print(np.allclose(*annotation_pair_to_compare))\n",
    "    print(np.allclose(*label_pair_to_compare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
